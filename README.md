# localAI 

This repository contains a Python scripts designed to help you use AI and Large Language Models (LLMs) directly on your laptop, specifically within the Obsidian note-taking app. At the moment just the script described below but others may be added.

## Converting PDFs for AI Analysis in Obsidian

One of the challenges of using LLMs is providing them with enough context to answer your questions effectively. This script addresses this by allowing you to convert a batch of PDF files into a single, AI-ready text file. This file can then be used with the SystemSculpt AI plugin in Obsidian to get insightful answers from your documents.

### How it Works

1. **PDF to Text Conversion:** The script uses the `pymupdf4llm` library to extract text from your PDF files. If this fails, it uses Optical Character Recognition (OCR) as a backup, ensuring all content is captured.

2. **Text Cleaning:**  The extracted text often contains unwanted elements like extra spaces, page numbers, and headers/footers. The script cleans this up, making the text more suitable for AI processing.

3. **Combining into a Single File:** All the cleaned text from your PDFs is combined into a single Markdown file (.md). This file is structured to work seamlessly with the SystemSculpt AI plugin.

4. **Ready for AI/LLM:** The generated Markdown file includes specific sections that an LLM will understand, such as "IDENTITY and PURPOSE," "OUTPUT INSTRUCTIONS," and "Context Material." This helps guide the AI and ensures you get the desired output.

### Using the Script

1. **Installation:** Make sure you have Python installed on your system. You'll also need to install the required libraries. You can do this by running 
```bash
pip install pymupdf4llm pytesseract pillow
```

2. **Obsidian Vault Setup:** 
    - Ensure you have the SystemSculpt AI plugin installed and configured in your Obsidian vault.
    - The script suggests default specific folder structure within your vault but also allows user input. You will be prompted to provide the location of your Obsidian vault and the names of your attachments folder and the folder containing your PDFs.  The script will create a file called `context.md` within the specified folder.

3. **Running the Script:** 
    - Place all the PDF files you want to analyze in the designated PDF folder within your Obsidian vault (or elsewhere if you have so specified)
    - Run the `pdf2text.py` script. 
    - The script will prompt you for some information about your folder locations. This is used to find your PDFs and save the output in the required location.

4. **Using with SystemSculpt:**
    - Open the generated `context.md` file in Obsidian.
    - You'll see your PDF content under the "Context Material" section.
    - Simply type your question at the end of the file under the "Question" heading.
    - Use the SystemSculpt hotkey to send the entire file to the AI.
    - ALTERNATIVLEY you can add the context.md file as context in a chat. Click the "C" button at the bottom of the screen to start a chat then click the "Context Files +" button and enter "context".  Then enter your questions.

### Benefits

- **Easy Context Loading:**  No more manually copying and pasting from multiple PDFs.
- **Seamless Obsidian Integration:** Designed to work easily with Obsidian and the "SystemsSculpt AI" plug in.

This script allows many PDF documents to be used as context for questions to an AI, making it possible to ask questions about the content of the PDF's or the contend of some PDFs related to other PDFs.  For example some quidance documents on a topic compared to a set of documents where one wishes to know if the guidance is complied with.  

### Note
The script will work taking files from a folder anywhere and writing the output file anywhere but the defaults are to locations in the vault itself so that they will get synchronised/backed up with the Vault.
In an example situation the set of PDF files to be used for context total size wa 6.8Mbytes but the extracted text file was about 0.5Mbytes.  That file was easily used to generate the required report (Analysis of a set of insurance documents against guidance) generated by asking questions from an AI with the text file as context.  (I used Google Gemeni Pro 1.5).  The cost of asking a question using that was less than half a doller.
